\chapter{Literatuurstudie}
%%% Leuke insmijter waarbij vertelt wordt dat software deployment oud is
In wat volgt, wordt een bespreking gegeven over het deployment proces maar ook van de verschillende problemen die horen bij dit proces.
Hiernaast zullen enkele case studies besproken worden en gaat er onderzocht worden hoe de verscheidene cases zijn omgegaan met de problemen die horen bij het deployment proces. 

\section{Software levenscyclus}\label{sec:softwareLevenscyclus}
%%% TODO aanvullen met info van andere bronnen
De levenscyclus van software deployment kan volgens \citet{softwareDeployment,hall1999cooperative} beschreven worden in verschillend stappen, namelijk:
\begin{itemize}
\item \emph{Release}: de software is volledig samengesteld uit pakketten die voldoende metadata bevatten om de verschillende bronnen te beschrijven waarvan het pakket afhangt.
\item \emph{Installatie}: de software moet overgebracht worden naar de client en geconfigureerd worden in voorbereiding op de activatie.
\item \emph{Activeren}: tijdens de activatie wordt de software uitvoering opgestart of worden de nodige triggers geplaatst om de executie op het gepaste tijdstip op te starten.
\item \emph{Deactiveren}: dit is tegengesteld aan activeren. Deze stap is voor nodig voordat een aanpassing of herconfiguratie kan uitgevoerd worden.
\item \emph{Updaten}: dit is het proces waarin de software wordt aangepast. Deze stap wordt vaak geactiveerd door het uitbrengen van een nieuwe versie van de software.
\item \emph{Deïnstallatie}: tijdens deze stap zal de geïnstalleerd software van het client systeem gehaald worden.
\end{itemize}
De enige fase van de levenscyclus die zich uitsluitend op de server afgespeeld is de release fase.
De rest van de fases spelen zich af op de verschillende client systemen.

\begin{figure}[!ht]
\centering
\makebox[0pt]{\includegraphics[scale=0.7]{afbeelding/softwareLevenscyclus.png}}
\caption{Levenscyclus van software \citep{carzaniga1998characterization}}
\label{fig:softwareLevenscyclus}
\end{figure}

In theorie zou het deployen van software een eenvoudige klus moeten zijn.
Aangezien software bestaat uit een set van bestanden, zou het deployen van software naar een doelcomputer slechts bestaan uit het kopiëren van de nodige bestanden.
Maar dit is vaak niet het geval.
Volgens \citet{dolstra2006purely} zijn er in de praktijk verschillende oorzaken die aan de basis liggen van een ingewikkeld deployment proces.
Deze oorzaken kunnen in twee grote categorieën ingedeeld worden, namelijk de omgevings- en onderhoudsproblemen.

\paragraph{Omgevingsproblemen}
In de eerste categorie ligt de nadruk vooral op correctheid.
Voordat de software geïnstalleerd wordt op een doelsysteem, wordt de doelomgeving ondervraagt naar alle eigenschappen: zijn de nodige programma's aanwezig, bestaan alle configuratie bestanden, \ldots .
Als deze eisen niet voldaan zijn, dan zal de software niet werken zoals gewenst.
\citet{dolstra2006purely} haalt enkele concrete voorbeelden aan van omgevingsproblemen:
\begin{itemize}
\item De deployment van software kan een gedistribueerd probleem zijn.
Software kan afhankelijk zijn van componenten draaiende op verwijderde systemen of van andere processen draaiende op het doelsysteem.  
\item Software is vaak afhankelijk van verschillende andere software componenten. 
Deze afhankelijkheden, of ook wel dependencies genoemd, moeten voor de deployment bepaald worden.
Dit proces is moeilijk en een fout kan pas laat ontdekt worden.
\item De dependencies moeten compatibel zijn met wat er verwacht wordt van de software.
Niet elke versie zal werken.
Sommige depencies vertonen build-time variaties.
De component kan dan gebouwd zijn met enkele optionele eigenschappen of eigenschappen die gekozen worden at build-time.
\item Sommige software componenten zijn afhankelijk van specifieke hardware.
Dit kan enkel verholpen worden door op voorhand te controleren welke hardware aanwezig is.
\end{itemize}

Uit deze concrete voorbeelden wordt al snel duidelijk dat er twee problemen zijn: de verschillende eisen van de software moeten geïdentificeerd worden en vervolgens moeten deze gerealiseerd worden in het doelsysteem.

\paragraph{Onderhoudsproblemen}
Naast de verschillende omgevingsproblemen, beschrijft \citet{dolstra2006purely} ook enkele onderhoudsproblemen.
Deze hebben te maken met het feit dat software moet kunnen ``evolueren''.
Om dit te ondersteunen, moeten allerlei actie zoals upgraden en updaten uitgevoerd wordens.
Enkele voorbeelden van zulke acties zijn:
\begin{itemize}
\item Tijdens het verwijderen van software, moeten alle componenten verwijderd worden.
Ondertussen mogen geen componenten verwijderd worden die nog in gebruik zijn door andere software.
\item Ook tijdens het updaten van software moet rekening gehouden worden met andere software.
Het updaten van een component kan voor problemen en failure zorgen in een andere component.
Een DLL-hell wordt best ten alle tijden vermeden.
\item Na het upgraden/updaten van een component, is het soms aangewezen om een roll back uit te voeren.
Zo'n actie kan overwogen worden als de upgrade belangrijke functionaliteiten van de software kapot maakt.
\end{itemize}

\section{Deployment strategieën}\label{sec:deployment}
De eerste stap in de softwarelevenscyclus bestaat uit het uitbrengen van de software.
De software moet bij de gebruiker terecht komen voordat hij/zij deze kan gebruiken.

\citet{deploymentMethods} haalt drie methodes aan om software te deployen: disk image-based deployment, behavior-based deployment en package-based deployments.
Bij disk image-based deployment worden de software en het besturingssysteem op eenzelfde moment naar de target node verzonden.
Er zullen verschillende image servers aanwezig zijn die elk een service aanbieden.
Het voordeel van deze strategie is dat, zolang de hardware en software vereisten voldaan zijn, de deployment bestaat uit een simpele read-write operatie.
Maar, zoals \citet{deploymentMethods} al aangeeft, deze methode is niet flexibel.
Voor de applicatie is flexibiliteit een must.
Iedere node bevat verschillende hardware en is verschillend geconfigureerd.
Een disk image-based deployment zal hierdoor niet gebruikt worden.
Het basis idee achter behavior-based deployment is het opnemen van de schijf operaties tijdens het deployen.
Als geweten is welke bestanden aangepast zijn, gecreëerd zijn, ... dan kan het proces nagebootst worden op andere nodes \citep{deploymentMethods}.
Zo een proces nabootsen is moeilijk.
Kernel operaties moeten getraceerd worden.
Deze methode biedt een verhoogde flexibiliteit aan ten opzichte van de disk image-based deployment maar dit is nog niet voldoende om deployments uit te voeren die uniek zijn per node.
De laatste techniek die \citet{deploymentMethods} aan haalt is package-based deployment.
Met behulp van een batch file, waarin alle nodige commando's aanwezig zijn, kan een installatie pakket gedeployed worden naar een target node.
Door het gebruik van een batch file wordt de flexibiliteit van de deployment verhoogd.

De geproduceerde software moet bij verschillende gebruikers terecht komen.
Een eenvoudige oplossing zou zijn dat slechts één gebruiker per keer geholpen wordt en dat iedere gebruiker zijn beurt afwacht.
Zo'n oplossing is misschien doenbaar mochten slechts een handvol gebruikers de applicatie nodig hebben maar dit is vaak niet het geval.
\citet{patterson2008data} haalt verschillende argumenten aan voor het distribueren van deze service en haalt enkele punten aan (betrouwbaarheid, bandbreedte en lage wachttijden) waar rekening mee moet gehouden worden alvorens een ontwerpbeslissing genomen wordt.
Zoals \citet{patterson2008data} aanhaalt, is het belangrijk dat alle gebruikers ten alle tijden de service kunnen gebruiken.
Hiernaast moet er rekening gehouden worden met de deployment strategie.
\citet{munch2012software} spreekt over verschillende strategieën om software uit te brengen:
\begin{itemize}
\item \emph{Big-bang}: iedere gebruiker van de applicatie zal op eenzelfde moment overschakelen van de oude naar de nieuwe software. 
Hierdoor wordt vermeden dat verschillende afdelingen met een andere versie van de software werken. 
Een nadeel is dat voldoende support aanwezig moet zijn om mogelijke problemen op te lossen.
\item \emph{Gefaseerd}: de nieuwe software zal bij een gefaseerde deployment enkel toegepast worden in specifiek geselecteerde projecten.
Als deze strategie voor een verlengde periode wordt toegepast, zullen verschillende versies van de software continu aanwezig zijn onder de gebruikers.
\end{itemize}
Aan beide strategieën zijn zowel voor- en nadelen gekoppeld.
Zo zal de big-bang strategie niet voordelig zijn om uit te voeren als de gebruikers verspreid zitten over de wereld.
Door het tijdsverschil zal de deployment bij sommige gebruikers plaatsvinden tijdens de werkuren en bij anderen midden in de nacht.
Het voordeel van de big-bang strategie is dat alle doelsystemen op een korte periode omgeschakeld worden naar de nieuwe versie van de applicatie. 
Het gebruik van de gefaseerde strategie kan het probleem met de tijdszones omzeilen maar deze strategie is ook niet ideaal aangezien het omschakelen van de software naar de nieuwe versie lang kan duren.
Een hybride oplossing is hier dus aangewezen.

\section{Software Dock Architectuur}\label{sec:softwareDock}
\citet{hall1999cooperative} bespreekt een interessante architectuur.
Het Software Dock research project creëerde een framework om de samenwerking tussen software producenten en gebruikers te verbeteren.
In Figuur~\vref{fig:softwareDock} wordt de ontworpen architectuur voorgesteld.
Er worden twee verschillende componenten gedefinieerd waarmee de producenten en gebruikers voorgesteld worden.
In de architectuur worden de verschillende producenten voorgesteld aan de hand van een release dock en worden de gebruikers voorgesteld als een field dock.
Aan deze docks worden verschillende agents gekoppeld.
Elke agent hoort typisch bij één stap uit de software levenscyclus die besproken wordt in Sectie~\vref{sec:softwareLevenscyclus}.
Naast de verschillende docks wordt ook een wide-area event systeem gedefinieerd.
Met dit systeem wordt de communicatie tussen de docks aangeboden.
\citet{hall1997architecture} legt alle stappen van de Software Dock architectuur uit.

\begin{figure}[!ht]
\centering
\makebox[0pt]{\includegraphics[scale=0.5]{afbeelding/softwareDockArchitectuur.png}}
\caption{Software Dock Architectuur \citep{hall1999cooperative}}
\label{fig:softwareDock}
\end{figure}

De release dock is een server die zich bevindt bij de software producent.
Dit dock biedt een release repository aan waar de gebruikers de nodige software selecteren voor deployment.
In de release dock wordt ieder release semantisch beschreven aan de hand van een Deployable Software Description file.
Elke release wordt vergezeld door enkele agents die de semantische betekenis lezen en zo de deployment kunnen uitvoeren.
Aan de hand van interfaces kunnen de agents aan de services en inhoud van de release dock.
Bij het wijzigen van een software release zal de release dock verschillende events afvuren.
Agents kunnen zich subscriben bij deze events en weten zo wanneer bepaalde handelingen uitgevoerd moeten worden \citep{hall1999cooperative}.

De field dock dient als een interface naar de gebruiker kant toe.
Deze interface biedt informatie over de resources en configuratie van het gebruiker systeem.
Op basis van deze informatie wordt een context opgebouwd waarin de releases van de resource dock worden gedeployed.
De agents die horen bij een release, docken zichzelf in de field dock en kunnen aan de hand van deze interface het gebruikers systeem ondervragen.
Aangezien kritische client-side informatie op een gestandaardiseerde wijze aangeboden wordt, met behulp van een geneste collectie van pair-values die een hiërarchie vormen, kan de installatie van de software gepersonaliseerd worden \citep{hall1999cooperative}.

\section{Event based services}\label{sec:event}
%%% TODO
Een belangrijk onderdeel van de software dock architectuur is de event service.
Deze handelt de communicatie af tussen de verschillende docks en is een spilfiguur in de architectuur.
Aan de hand van \citet{pietzuch2002hermes} en \citet{carzaniga2001design} is het mogelijk om een bespreking te geven over hoe de event service geïmplementeerd kan worden.

Meeste middleware systemen zijn invocation-based systemen waarbij het request/response paradigma gebruikt wordt om de communicatie tussen client en server te onderhouden.
Een client verzoekt een service van de server, waar de server vervolgens op antwoord.
Het toepassen van deze strategie is doenbaar in een omgeving met een beperkt aantal clients en servers.
Om een grootschalig netwerk op te bouwen en om te kunnen gaan met een dynamische omgeving moet een andere manier van communiceren gebruikt worden.
Publish/subscribe systemen bieden een oplossing voor deze problemen.
Clients, event subscribers, tonen hun interesse voor een bepaald onderwerp en servers, event publishers, produceren een event die naar alle geïnteresseerden wordt doorgestuurd.
Een algemeen voorbeeld is terug te vinden in Figuur~\vref{fig:pubsubArchi}.
Door deze manier van communiceren te hanteren, ontstaat een natuurlijke ondersteuning voor many-to-many relaties tussen de clients en servers.
De twee worden ook van elkaar ontkoppeld.
Voor de client maakt het niet uit welke publisher de producent is van een event.
Hiernaast moet de server niet weten wie allemaal de events ontvangt die hij produceert \citep{pietzuch2002hermes}.

\begin{figure}[!ht]
\centering
\makebox[0pt]{\includegraphics[scale=0.5]{afbeelding/pubsubArchi.png}}
\caption{Publish/Subscribe voorbeeld \citep{pietzuch2002hermes}}
\label{fig:pubsubArchi}
\end{figure}

Een naïeve aanpak, volgens \citet{carzaniga2001design}, is het gebruiken van één centrale server waar alle subscripties worden bijgehouden, waar alle events toekomen, waar de bestemming van het event beslist wordt en waar het event wordt doorgestuurd naar de gepaste subscribers.
Deze strategie is eenvoudig te implementeren maar deze werkt de schaalbaarheid tegen.
Dit was ook al duidelijk in Figuur~\vref{fig:pubsubArchi} waar verschillende ``Brokers'' aanwezig zijn.
Het is belangrijk om stil te staan bij enkele ontwerp beslissingen zodanig dat de service die in Figuur~\vref{fig:pubsubService} zichtbaar is, implementeerbaar is.

\begin{figure}[!ht]
\centering
\makebox[0pt]{\includegraphics[scale=0.5]{afbeelding/pubsub.png}}
\caption{Publish/Subscribe service \citep{carzaniga2001design}}
\label{fig:pubsubService}
\end{figure}

Naast de architectuur is het belangrijk om te weten wat wordt verzonden en op welke manier.
\citet{carzaniga2001design} haalt een structuur aan waarin een event beschreven wordt als een set van attributen.
Ieder attribuut bestaat uit een type, naam en waarde.
De naam van een attribuut is een string en het type komt uit een set van primitieven die terug gevonden worden bij de meeste hedendaagse programmeertalen.
Een voorbeeld van zo'n event is terug te vinden in Figuur~\vref{fig:pubsubNot}

\begin{figure}[!ht]
\centering
\makebox[0pt]{\includegraphics[scale=0.5]{afbeelding/pubsubNot.png}}
\caption{Publish/Subscribe Event \citep{carzaniga2001design}}
\label{fig:pubsubNot}
\end{figure}

\section{Case studies}\label{sec:caseStudies}
Door de jaren heen zijn er verschillende technologieën ontwikkeld die het probleem van software deployment aanpakken.
In wat volgt, worden enkele van deze technologieën besproken gebaseerd op enkele case studies die \citet{softwareDeployment} aanreikt.

\subsection{Java Beans}
Enterprise JavaBeans (EJB) zijn een standaard voor het bouwen van server-side componenten.
De EJB's zijn speciaal ontworpen voor het vereenvoudigen van de deployment.
\citet{softwareDeployment} beschrijft JavaBeans als eenheden van business logic in een component die uitgevoerd wordt in een container.
De verschillende containers zorgen voor een abstractie van de hosting omgeving en bieden verscheidene services aan.
Een JavaBean moet ingepakt worden volgens de specificaties die Sun Microsystems oplegt.
Met deze standaard is het mogelijk om verschillende management en deployment tools te schrijven die de EJB's kunnen beïnvloeden.
Enterprise JavaBeans worden ingepakt in de standaard Java JAR file, samen met een XML deployement descriptor.
De descriptor beschrijft de verschillende eigenschappen van de bijhorende EJB.

De Enterprise JavaBeans zijn volgens \citet{softwareDeployment} fijnkorrelige en taalafhankelijke oplossing voor het deployment probleem.
Door het isoleren van de Beans door middel van een gestandaardiseerde container interface zullen Enterprise JavaBeans zo een oplossing vinden voor het deployment probleem.
Hierdoor moeten de EJB's zodanig ontworpen worden dat ze voldoen aan de eisen van de interface.
Enterprise JavaBeans hebben geen idee van het op afstand installeren van componenten.
Een groot probleem bij EJB's is dat referenties naar afhankelijke beans gebeurd via niet unieke namen.
Twee verschillende beans met eenzelfde naam moeten hierdoor manueel herladen worden zodanig dat de bindings up-to-date zijn \citep{rutherford2002reconfiguration}.

\subsection{Redhat package manager}
In Linux wordt de Redhat package manager (RPM) het vaakst gebruikt voor de deployment van software.
Met hulp van de RPM is het mogelijk om enkele operaties uit te voeren zoals onder andere installatie, updaten, \ldots .
De operaties worden ondersteund door een databank die alle informatie en details van de geïnstalleerde pakketten bevat.
Een RPM pakket bestaat uit executables gecombineerd met configuratie bestanden en documentatie.
Doordat een pakket executables bevat, zal een pakket gekoppeld zijn aan het besturingssysteem van de host \citep{bailey1997maximum}.
Naast de RPM files bevat een pakket verschillende scripts geschreven in de standaard Unix scripting taal.
De verscheidene scripts zijn ingedeeld in sets horende bij een specifieke taak.
Bij een error moet een roll back uitgevoerd worden.
Dit is de taak van de script schrijver \citep{softwareDeployment}.

De Redhat Package Manager is in tegenstelling met de EJB's een grofkorrelige, taal onafhankelijke maar besturingssysteem afhankelijke oplossing.
Het grootste probleem van RPM schuilt in de afhankelijkheden tussen de pakketten.
Niet alle afhankelijkheden zijn explicite gemodelleerd en de afhankelijkheden die wel gemodelleerd zijn, zijn gevormd met de nadruk op de inhoud en niet op de pakketten zelf \citep{softwareDeployment}.  

\subsection{ATLAS}\label{sec:ATLAS}
Om in de ATLAS samenwerking om te gaan met de grote hoeveelheid bronnen, is er een volledig automatisch installatie systeem ontworpen voor het LCG/EGEE project, LHC Computing Grid/Enabling Grids for E-sciencE \citep{bird2005lhc}. 
\citet{salvo2008atlas} beschrijft de architectuur van het ontworpen systeem.
Het ontwerp van het installatie systeem werd gebaseerd op het Light Job Submission Framework for installation, ook wel LJSFi.

\begin{figure}[!ht]
\centering
\makebox[0pt]{\includegraphics[scale=0.7]{afbeelding/ljsfiArchitectuur.png}}
\caption{LJSFi Architectuur \citep{salvo2008atlas}}
\label{fig:ljsfiArchi}
\end{figure}

De architectuur van het framework is zichtbaar in Figuur~\vref{fig:ljsfiArchi}.
Het framework vormt een dunne laag over de middleware van Grid.
De kern van het systeem bestaat uit de installatie database en de command line interface (CLI).
De laatste zorgt voor de interacties met de Grid middleware.
Met hulp van de installatie database kan de CLI verschillende taken en job informatie opslaan.
Aan de hand van deze informatie kunnen installaties uitgevoerd worden.
De installatie databank staat in contact met alle componenten van het framework.
Zo kan de status van verscheidene acties en configuraties van verschillende taken opgeslagen worden.

Naast deze twee grote componenten bevat LJSFi modules en extensies waarmee installatie aanvragen afgehandeld worden.
Het systeem bevat drie verschillende componenten:
\begin{itemize}
\item \textbf{RAI module} De Request An Installation module dient als web interface voor het ontvangen van user-driven installatie aanvragen.
\item \textbf{AIR module} De Automatic Installation Requester schiet in actie als software release aangeduid staan als productie of auto-installatie.
De module verwijdert of installeert de software op alle sites waar de software nog niet gepubliceerd is.
Door de AIR module periodiek te gebruiken, zullen de nodige aanvragen snel afgehandeld worden.
\item \textbf{InAgent module} Met de InAgent module wordt het mogelijk om volledig geautomatiseerde installatieprocessen te voorzien.
Iedere 10 minuten wordt de Installation database gelezen en via de CLI interface worden de nodige installatieprocessen opgestart.
Elk installatieproces wordt bijgestaan door een installation agent.
De agent zal instaan voor het updaten van de Installatie database met real-time informatie die zichtbaar is online.
\end{itemize}

Naast de verscheidene automatische services biedt LJSFi enkele gebruiker services aan.
Een gebruiker kan zich subscriben voor bepaalde acties op een doel systeem.
Als deze actie wordt uitgevoerd dan krijgt de gebruiker een mail.
Hiernaast kan een gebruiker een software release vastpinnen zodat deze niet verwijderd kan worden door het systeem.

Het installatieproces wordt uitgevoerd in drie verschillende stappen.
In een eerste stap wordt een site check uitgevoerd door een pilot job naar de site te sturen.
Als de check succesvol uitgevoerd wordt, kan het installatieproces beginnen.
De acties tijdens het installatieproces worden uitgevoerd door softwaremanagement scripts.
Op het einde van het proces, haalt het systeem de job output en exit code op.
De laatste wordt opgeslagen in de Installation database.

\citet{Obreshkov2008244} bespreekt hoe het ATLAS project te werk gaat bij het inpakken van alle nodige software.
Het ATLAS project gebruikt CMT \citep{cmt} als configuratie manager.
Met behulp van een configuratie bestand weten verscheidene tools hoe ze een pakket moeten afhandelen.
\citet{packAtlas} spreekt ook over CMT als informatiebron voor het ophalen van meta-data.
Aan de hand van deze data kan een Pacman pakket geproduceerd worden.
Met behulp van een ``Pacman file'' is geweten hoe de ingepakte software behandelt moet worden.

\subsection{ORYA}\label{sec:ORYA}
\citet{lestideau2003providing} legt uit hoe ORYA (Open enviRonment to deploY Applications) verschillende deployment functionaliteiten aanbiedt aan gedistribueerde, autonome entiteiten zoals workstations en servers.
Aan de hand van een deployment PSEE \citep{belkhatir2007adele} wordt het mogelijk om het installatieproces te automatiseren.

In het ontwerp van ORYA worden er drie verschillende entiteiten besproken die nodig zijn om het automatische installatieproces mogelijk te maken.
\begin{itemize}
\item \textbf{Applicatie Server} De applicatie server bevat nodige informatie nodig voor de installatie.
Hieronder bevindt zich onder andere een pakket met de nodige resources en een manifest waarin de afhankelijkheden, beperkingen en features staan.
\item \textbf{Target} De target is het doel waarop de deployment uitgevoerd wordt.
Iedere target wordt beschreven door de verschillende applicaties die al aanwezig zijn en de fysische beschrijving.
\item \textbf{Deployment Server} De deployment server vormt de kern van de deployment omgeving en staat in voor het uitvoeren van de deployments. 
De deployment server zoekt de nodige pakketten, voert een transfer van de pakketten uit en installeert de applicatie.
Op het einde moet de deployment server garanderen dat vorige programma's correct blijven functioneren.
\end{itemize}

\citet{lestideau2003providing} beschrijft verder de verschillende modellen die gehanteerd worden om een succesvolle deployment uit te voeren.
In Figuur~\vref{fig:deploymentModel} is het deployment proces model terug te vinden.
Een deployment proces zal bestaan uit verschillende basis activiteiten en deployment processen.
Iedere activiteit wordt uitgevoerd door een agent.

\begin{figure}[!ht]
\centering
\makebox[0pt]{\includegraphics[scale=0.7]{afbeelding/deploymentModelORYA.png}}
\caption{Deployment proces model \citep{lestideau2003providing}}
\label{fig:deploymentModel}
\end{figure}

Een toegepast voorbeeld van een deployment aan de hand van dit model is terug te vinden in Figuur~\vref{fig:deploymentVoorbeeld}.
Een basis activiteit wordt voorgesteld aan de hand van een grijze rechthoek en een deployment proces aan de hand van een witte rechthoek.
In het voorbeeld zijn dus vier deployment processen aanwezig en 3 basis activiteiten.

\begin{figure}[!ht]
\centering
\makebox[0pt]{\includegraphics[scale=0.7]{afbeelding/deploymentVoorbeeld.png}}
\caption{Voorbeeld van een deployment \citep{lestideau2003providing}}
\label{fig:deploymentVoorbeeld}
\end{figure}

Aan de hand van deze structuur wordt het mogelijk om het volledige deployment proces voor te stellen.

\subsection{Nix}
\citet{dolstra2006purely} bespreekt hoe Nix systemen omgaan met het deployment probleem.
Nix houdt verschillende componenten bij in de component store waarbij iedere component een set van bestanden is.
De componenten worden van elkaar gescheiden door een unieke naam.
Dit wordt bekomen door een cryptografische hash op te nemen in de naam.
Nix biedt geen software deployment aan.
Het biedt verscheidene mechanismen aan waarmee verschillende deployment beleid beschikbaar worden.
Met de volgende deployment models is het mogelijk om in Nix de Nix expressies (de bouwstenen van de Nix componenten) te verspreiden:
\begin{itemize}
\item \textbf{Handmatige download} Een gebruiker kan zelf pakketten downloaden in de vorm van tar archieven, deze zelf uitpakken en vervolgens installeren.
Deze strategie is arbeidsintensief en maakt het moeilijk om alles up-to-date te houden. 
\item \textbf{Updaten aan de hand van een versie management systeem} Een andere strategie is het gebruik van een versie management systeem.
Hiermee is het up-to-date houden van de pakketten zeer eenvoudig.
\item \textbf{Kanalen} Een verdere uitbreiding zijn de kanalen.
Een kanaal is een URL naar een tar archief die de nodige Nix expressies bevat.
Met deze strategie is het even eenvoudig om pakketten te installeren en up-to-date te houden.
\item \textbf{One-click installatie} Als er enkel één pakket geïnstalleerd moet worden, dan is de one-click installatie de eenvoudigste optie.
Via de website van de verdeler kan een link gebruikt worden om het nodige pakket te installeren.
\end{itemize}

\subsection{Ansible}
Als laatste case studie wordt Ansible besproken.
Ansible is een open source IT configuratie management, deployment en organisatie tool.
de architectuur van Ansible bestaat uit een agentless push model.
Dit wil zeggen dat er geen additionele software nodig is op de client toestellen.
Dit wordt behaald door gebruik te maken van de remote manegement frameworks aanwezig op de toestellen, SSH voor Linux en UNIX en WinRM voor Windows.
Door geen agents te gebruiken, zal Ansible geen resources gebruiken zolang de Ansible het systeem niet aan het gebruiken is \citep{ansible}.

\citet{ansible} beschrijft verder dat Ansible gebruik maakt van \emph{Playbooks} voor de organisatie van de IT omgevingen.
Playbooks zijn YAML\footnote{Een human-readable data serialisatie taal (Een superset van JSON)} definities van taken die beschrijven hoe een taak moet geautomatiseerd worden.
Een Playbook bestaat uit een aantal ``plays'' die uitgevoerd kunnen worden op een set van hosts, ook wel een ``inventory'' genoemd.
Iedere play bestaat uit een set van taken die op een subset van de inventory uitgevoerd kan worden.
Een task zelf voert een Ansible module uit\footnote{Een klein stuk code met een specifieke taak}.

Hiernaast is het mogelijk om de mogelijkheden van Ansible uit te breiden.
Modules kunnen zelf geschreven worden in eender welke taal met als enige beperking dat een JSON bestand als input moet gegeven worden en dat een JSON bestand gegenereerd moet worden.
De inventory van een Playbook kan dynamisch ontdekt worden at runtime.

\section{Rollback}\label{sec:rollback}
Het deployen van software op een doelsysteem brengt verscheidene problemen met zich mee.
In de levenscyclus van software zijn er verschillende staten waarin de software moet aangepast worden.
Zoals reeds besproken in Sectie~\vref{sec:softwareLevenscyclus}, zijn er verschillende problemen die kunnen optreden tijdens één van deze staten.
In de volgende secties gaan verschillende mechanismen besproken worden waarmee de verscheidene problemen aangepakt kunnen worden.

\subsection{Rollback strategieën}
\citet{srinivasan2004flashback} spreekt over drie manieren waarop rollback strategieën geïmplementeerd worden in hedendaagse systemen.
Checkpointing, main-memory transactions en software rejuvination zijn strategieën die vaak gebruikt zijn.

\paragraph{Checkpointing}
Checkpointing is een eenvoudige recovery strategie.
De staat van een programma wordt periodiek opgeslagen in een bestand op een extern opslagmedium.
Deze kan, na het falen van het programma, gebruikt worden om te herstellen van fouten \citep{plank1994libckpt}.
Bij een checkpointing systeem wordt de volledige staat van het programma opgeslagen.
Dit zorgt voor een verhoogde overhead waardoor het niet mogelijk is om frequent een checkpoint uit te voeren \citep{srinivasan2004flashback}.

Door gebruik te maken van incrementele checkpoints is het evenwel mogelijk om dit probleem aan te pakken.
Enkel de veranderingen van de laatste checkpoint worden opgeslagen in een nieuwe checkpoint.
Het deel dat niet is aangepast, kan hersteld worden aan de hand van de vorige checkpoint.
Dankzij deze strategie is het mogelijk om de hoeveelheid data die moet worden opgeslagen te verkleinen.
Hierdoor zullen wel verschillende recovery bestanden nodig zijn.
Het is aangewezen om op regelmatige tijdstippen de verschillende recovery bestanden samen te voegen tot één bestand \citep{plank1994libckpt, elnozahy2002survey}.

\paragraph{Main-memory transactions}
Een andere rollback strategie zijn de main-memory transactions.
Systemen die deze transacties ondersteunen bezitten vaak de mogelijkheid om terug te keren naar een vorig executie punt.
Om deze strategie te kunnen implementeren, moeten applicaties gebruik maken van het transactie programmeermodel.
Waardoor de keuzevrijheden van de programmeur beperkt worden \citep{srinivasan2004flashback}.

\paragraph{Software rejuvenation}
\citet{huang1995software} definieert software rejuvination als volgt:
\begin{displayquote}
``Software rejuvenation is the concept of gracefully terminating an application and immediately restarting it at a clean internal state.''
\end{displayquote}
Tijdens het langdurig uitvoeren van een programma treedt \emph{process aging} op.
Door geheugenlekken, niet vrijgegeven bestandlocks, data corruptie, \ldots zal de performantie van het uitvoerende programma aangetast worden waardoor het programma uiteindelijk faalt.
Door het heropstarten van de applicatie worden eventuele fouten uit het systeem gehaald en wordt de software verjongd.
Meeste studies over software rejuvenation focussen vooral op het herstarten van de volledige applicatie en werken dus niet op een fijnkorrelige schaal \citep{srinivasan2004flashback}.

\subsection{Virtualisatie}\label{sec:virtualisatie}
\citet{softwareDeployment} brengt virtualisatie ter sprake.
Door middel van virtualisatie wordt de complexiteit die ontstaat door de interactie tussen het programma, de installatieomgeving en de uitvoeringsbeperkingen gelimiteerd.
Door het creëren van een perfecte omgeving komen deze problemen niet voor.
Er zijn verschillende voordelen gekoppeld aan het gebruiken van een virtuele machine.
Bijvoorbeeld, besturingssystemen op verschillende hardware platformen eisen verschillende drivers en deze drivers hebben misschien afhankelijkheden op een bepaalde firmware en BIOS.
Een guest OS draaiende op een virtuele machine heeft deze eisen niet \citep{shumate2004implications}.

%%% TODO? \citep{shumate2004implications} gebruiken om image deployement uit te leggen... Is dit wel nodig aangezien het niet echt de scope is waarin een image gebruikt zou worden.

\subsection{Docker}\label{sec:docker}
Virtualisatie is niet de enige techniek die gebruikt kan worden om rollbacks te vermijden.
Docker containers is een technologie waarmee een stuk software wordt ingepakt in een volledig filesysteem dat alle benodigdheden bevat om correct te functioneren.
Hierdoor zal de software overal op eenzelfde manier draaien, ongeacht de omgeving \citep{dockerMain}.
Docker containers is niet hetzelfde als virtuele machines.
\citet{dockerEbook} bespreekt de twee aan de hand van een vergelijking.
In de vergelijking worden virtuele machines voorgesteld als huizen terwijl Docker containers worden voorgesteld als appartementen.

De huizen staan volledig op zichzelf en bieden bescherming tegen ongewenste gasten.
Ze hebben een eigen infrastructuur met hun eigen water, verwarming, \ldots .
Hiernaast zal ieder huis op zijn minste een badkamer, living, slaapkamer en keuken hebben.
Het vinden van een klein huis is een ganse klus en vaak zal een huis meer bevatten dan nodig is want dat komt door de manier waarop huizen gebouwd worden.

Appartementen bieden ook bescherming tegen ongewenste gasten, maar zij zijn gebouwd rond een gemeenschappelijke infrastructuur.
Het appartementsgebouw biedt gemeenschappelijk water, verwarming, \ldots  aan, aan elk appartement.
Elk appartement verschilt ook nog van grootte.
Er bestaan kleine appartementen maar ook grote met meerder slaapkamers.
Men huurt enkel hetgeen dat nodig is.

\begin{figure}[!ht]
\centering
\makebox[0pt]{\includegraphics[scale=0.5]{afbeelding/dockerVsVM.png}}
\caption{Architectuur van Virtuele Machine ten opzichte van Docker \citep{dockerMain}}
\label{fig:VMvsDocker}
\end{figure}

In Figuur~\vref{fig:VMvsDocker} zijn de architecturen van virtuele machines en Docker terug te vinden.
Het verschil tussen beiden wordt al snel duidelijk.
Een virtuele machine zal typisch de applicatie, de nodige binaries en bibliotheken en een volledig besturingssysteem bevatten.
Een container bevat de applicatie en de verschillende dependencies maar de kernel wordt gedeeld met alle andere containers en gedragen zich als een geïsoleerd proces in de user space van het host besturingssysteem.

\citet{chamberlain2014using} bespreekt kort hoe Docker werkt.
Docker is een platform dat gebruik maakt van de Linux Containers (LXC de user-space control package voor Linux Containers) om software te encapsuleren.
LXC is een virtualisatie techniek waarmee virtuele omgevingen in Linux opgebouwd kunnen worden.
De containers zullen processen van elkaar sandboxen zodanig dat een proces een ander niet kan beïnvloeden \citep{merkel2014docker}.
Docker zal de LXC software uitbreiden waardoor deployment, distributie en versioning mogelijk wordt.
Naast LXC gebruikt Docker AuFS (Advanced Multi-Layered Unification Filesystem) als het filesysteem voor de containers.
Doordat het filesysteem gelaagd is, is het mogelijk om verschillende filesystemen over elkaar te leggen.

\citet{merkel2014docker} vergelijkt de twee virtualisatie technieken en bespreekt de verschillende tussen de twee.
Bij virtuele machines moet voor iedere virtuele machine een besturingssysteem geïnstalleerd worden.
Al deze besturingssystemen verbruiken RAM, CPU en bandbreedte.
Containers zullen piggybacken op het bestaande host besturingssysteem.
Hierdoor zal het resource gebruik efficiënter zijn.
Een container is goedkoop waardoor het creëren en verwijderen van containers een snelle operatie.
Dit komt omdat er enkel een proces moet afgesloten worden in tegenstelling tot het afsluiten van een volledig besturingssysteem.
Een voordeel van de VMs ten opzichte van Docker is hun maturiteit.
VMs bestaan langer en hebben zichzelf kunnen bewijzen in verschillende situaties.

\subsection{Technologieën}\label{sec:technologieen}
Implementaties in verschillende programmeertalen, verschillende data representatie formats of incompatibele runtime environments kunnen aan de basis liggen voor een lastige integratie van computerprogramma's.
Door gebruik te maken van additionele software, wordt het mogelijk om het gat tussen de verschillen te overbruggen  \citep{callahan1998software}.
Het Python testraamwerk is een verzameling van verschillende drivers en bibliotheken elk met een eigen implementatie.
In de volgende Sectie wordt er gekeken naar verschillende software oplossingen waarmee dit probleem opgelost kan worden.

Om de verschillende technologieën te vergelijken werd een algemeen testscenario uitgedacht.
Het scenario ziet er als volgt uit: er moet een installer gemaakt worden waarmee twee verschillende pakketten (die drivers en bibliotheken moeten voorstellen) geïnstalleerd moeten worden.
Hierna werd er onderzocht hoe één van de twee pakketten geüpdatet kon worden.
Door de technologieën te onderwerpen aan een test, wordt het mogelijk om de voor- en nadelen van iedere technologie te achterhalen.
Hiernaast wordt het ook mogelijk om de technologieën te vergelijken aangezien zij eenzelfde functionaliteit moeten voorzien.

\begin{table}[]
\centering
\begin{tabular*}{\linewidth}{clll}
\hline
\multicolumn{4}{p{\linewidth}}{\centering \textbf{WiX Toolset}}                    \\ 
\multicolumn{2}{p{0.5\linewidth}}{\centering Pro} & \multicolumn{2}{p{0.5\linewidth}}{\centering Cons} \\ \hline
\multicolumn{2}{p{0.5\linewidth}}{Diepe integratie met Windows \par Mogelijkheid om externe executables te includeren}   & \multicolumn{2}{p{0.5\linewidth}}{XML structuren zorgt voor veel overhead \par Niet cross-platform}    \\ \hline
\multicolumn{4}{p{\linewidth}}{\centering \textbf{NSIS}}                           \\ 
\multicolumn{2}{p{0.5\linewidth}}{\centering Pro} & \multicolumn{2}{p{0.5\linewidth}}{\centering Cons} \\ \hline
\multicolumn{2}{p{0.5\linewidth}}{Scripting taal \par Verschillende plug-ins beschikbaar}   & \multicolumn{2}{p{0.5\linewidth}}{ Niet cross-platform \par Geen structuur voor packages}    \\ \hline
\multicolumn{4}{p{\linewidth}}{\centering \textbf{Chocolatey}}                     \\ 
\multicolumn{2}{p{0.5\linewidth}}{\centering Pro} & \multicolumn{2}{p{0.5\linewidth}}{\centering Cons} \\ \hline
\multicolumn{2}{p{0.5\linewidth}}{Volledige deployment infrastructuur al aanwezig}   & \multicolumn{2}{p{0.5\linewidth}}{Niet cross-platform \par Command-line tool}    \\ \hline
\multicolumn{4}{p{\linewidth}}{\centering \textbf{Qt Installer Framework}}         \\ 
\multicolumn{2}{p{0.5\linewidth}}{\centering Pro} & \multicolumn{2}{p{0.5\linewidth}}{\centering Cons} \\ \hline
\multicolumn{2}{p{0.5\linewidth}}{Cross-platform \par Mogelijkheid om externe executables te includeren}   & \multicolumn{2}{p{0.5\linewidth}}{XML structuren zorgt voor veel schrijfwerk \par Enkel Linux installer maken in Linux} \\ \hline
\end{tabular*}
\caption{Voor- en nadelen van de verschillende technologieën}
\label{tab:voorNadelen}
\end{table}

\subsubsection{WiX Toolset}
Windows installer XML Toolset is een set van build tools waarmee Windows Installer packages gemaakt worden van XML broncode.
De toolset is geschreven in C\# en heeft het .Net framework nodig om te kunnen functioneren.
Bron code wordt gecompileerd en vervolgens gelinkt om een executable te maken.
Met de toolset kunnen .msi installatie pakketten, .msm merge modules en .msp patches gecombineerd worden tot een Windows executabel.\citep{wixToolset}.

Aan deze technologie zijn verschillende voor- en nadelen verbonden (zie Tabel~\ref{tab:voorNadelen}).
Een fragment van de WiX toolset code is terug te vinden in Listing~\vref{list:wix}.
De WiX toolset maakt installer uitsluitend bedoelt voor de Windows installation engine.
Hierdoor worden verscheidene functionaliteiten eenvoudig te gebruiken, zoals het maken van uitzonderingen in de Windows Firewall.
Door gebruik te maken van de Windows installation engine is het niet mogelijk om de executabel te gebruiken in Linux omgevingen\footnote{Dit kan eventueel omzeilt worden door het gebruik te maken van software zoals Wine \citep{amstadt1994wine}. Als geen alternatieven aanwezig zijn, dan is deze strategie eventueel het overwegen waard.}.
WiX maakt gebruik van XML broncode om verschillende elementen te definiëren.
\citet{xmill} geeft al aan dat XML niet een van de meest efficiënte dataformaten is, maar het verhoogd de flexibiliteit wel.
Het creëren van een XML bestand met de hand is een langdradig en moeilijk werk.

\subsubsection{NSIS}
Nullsoft Scriptable Install System is een open source systeem waarmee Windows installers gemaakt kunnen worden.
Zoals de naam aangeeft, is NSIS script-based.
Hierdoor bevatten installers de nodige om verschillende installatie taken uit te voeren.
Door de grote gebruikersbasis is een grote hoeveelheid plug-ins en scripts beschikbaar.
Alle plug-ins en scripts kunnen op een eenvoudige manier aan een installer toegevoegd worden voor een verhoogde functionaliteit \citep{nsisMain}.

De voor- en nadelen verbonden aan NSIS zijn terug te vinden in Tabel~\ref{tab:voorNadelen}.
Met de scripting taal van NSIS is het mogelijk om eenvoudige installer te definiëren (een voorbeeld hiervan is terug te vinden in Listing~\vref{list:nsis}).
De scripting taal is intuïtiever te gebruiken in vergelijking met de XML bestanden van Wix Toolset.
Dankzij grote hoeveelheid aan plug-ins die aanwezig zijn, is het eenvoudig om een installer te creëren met verschillende functionaliteiten.
De gecreëerde installer is een Windows executabel en de opmerking gegeven bij de WiX Toolset is hier ook van toepassing.
Het feit dat NSIS bedoelt is om eenvoudige installers te maken zorgt ervoor dat het niet mogelijk is om aparte pakketten te definiëren.
Ieder pakket kan wel een eigen configuratie hebben maar dit wordt allemaal toegevoegd aan één script.
Bij een grote hoeveelheid aan pakketten leidt tot wanorde en is er geen globaal overzicht.
NSIS beidt ook geen mogelijkheden aan om geïnstalleerde software up te daten.
Om die eigenschappen toe te voegen moet er beroep gedaan worden op andere software.

\subsubsection{Chocolatey}
Volgens \citet{chocoAbout} is Chocolatey een package mangager voor Windows net zoals apt-get voor Linux is.
Het is ontworpen als een gedecentraliseerd framework met als doel het snel installeren van applicaties en tools.
Chocolatey werd gebouwd boven op de NuGet infrastructuur gecombineerd voor het verspreiden van de packages en gebruikt PowerShell voor een gepersonaliseerde installatie.

In Tabel~\ref{tab:voorNadelen} zijn de verschillende voor- en nadelen gekoppeld aan Chocolatey terug te vinden.
Het grootste voordeel dat bekomen wordt bij het gebruiken van een package manager is het al bestaan van een deployment infrastructuur. 
Na het installeren van Chocolatey op de client kunnen alle nodige packages voor het framework geïnstalleerd worden.
Hiernaast kunnen scripts gekoppeld worden aan iedere package zodanig dat een aangepaste installatie mogelijk is.
Net zoals apt-get voor Linux, is Chocolatey te gebruiken in de command-line.
Dit is vooral een nadeel naar gebruiksvriendelijkheid toe aangezien er vanuit wordt gegaan dat de gebruikers amper tot geen ervaring hebben met de command-line in Windows/Linux.
Het grootste nadeel aan deze technologie is, net zoals de vorige opties, het niet cross-platform zijn.

\subsubsection{Qt Installer Framework}
Het Qt Installer Framework biedt een set van tools aan voor het creëren van installers op verschillende platformen.
Aan de hand van een set van pagina's wordt de gebruiker door het installatie-, update- en verwijderproces.
Hierbij kunnen scripts gebruikt worden om het proces te vereenvoudigen \citep{qtDoc}.

Aan deze technologie zijn verschillende plus- en minpunten verbonden.
Een vergelijking van de verschillende voor- en nadelen is terug te vinden in Tabel~\ref{tab:voorNadelen}.
Het grootste voordeel van het Qt Installer framework is het cross-platform zijn.
Hierdoor is het mogelijk om installers te maken voor zowel Windows als Linux.
Een nadeel dat hieraan verbonden is, is dat een Linux installer enkel kan gemaakt worden op in een Linux omgeving.
Het is niet mogelijk om een Linux installer te maken op een Windows systeem.
Hiernaast is het wel mogelijk om voor ieder pakket een aparte installatieprocedure te implementeren.

%%% TODO Schrijven over het gebruiken van Windows .exe in Linux? Bijvoorbeeld hoe Wine misschien een oplossing is?

%%% TODO Schrijven over de test setup voor de verschillende technologieën die gebruikt is tijdens de stage?